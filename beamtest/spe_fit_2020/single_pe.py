"""
This script analyzes the single pulse data with a random time window, extracts the single pe peak height.
Inputs: csv file generated by the script "analyze_waveform.py" and the background estimate from "analyze_background.py"
Outputs: multiple figures and a csv file for single pe peak height
"""
import pandas as pd
import numpy as np
import os
from matplotlib import pyplot as plt
from scipy.optimize import curve_fit


def gaus(x, p0, p1, p2):
    return p0*np.exp(-(x-p1)**2/(2*p2**2))


def auto_split(n):
    test = int(np.sqrt(n))
    if np.square(test) >= n:
        return test, test
    elif (test + 1)*test >= n:
        return test + 1, test
    else:
        return test + 1, test + 1


data_dir = r'/work/halld2/home/boyu/solid_pmt_test/beamtest/spe_fit_2020'
output_dir = r'/work/halld2/home/boyu/solid_pmt_test/beamtest/spe_fit_2020'
run = 160
splits = np.arange(0, 1)
min_peak = 1.0
random_range = (5, 30)


df = pd.concat([pd.read_csv(os.path.join(data_dir, 'run{}_{}_single.csv'.format(run, s)), index_col=0)
                for s in splits], axis=0).reset_index(drop=True)
df = df[df['trg_peak'] > 0]

# calculate number of hits
# channels = sorted(list(set(['_'.join(x.split('_')[0:-1]) for x in df.columns if x.startswith('Cer')])))
channels = ['Cer{}{}_5'.format(i, j) for i in range(1, 5) for j in range(1, 5)]
pchs = [c + '_peak' for c in channels]
df.loc[:, 'nhits'] = (df[pchs] > min_peak).sum(axis=1)
df = df[df['nhits'] > 0]

# backgrounds
df_bk = pd.read_csv(os.path.join(data_dir, 'run{}_bk_fit.csv'.format(run)), index_col=0)

# plot triggers
triggers = {
    'Peak ADC Value': (df['trg_peak'], np.arange(0, 1500, step=10)),
    'Peak Sample Position': (df['trg_pos'], np.arange(0, 62, step=1)),
}

bprops = dict(boxstyle='round', facecolor='wheat', alpha=0.5)
fig, axs = plt.subplots(2, 1, figsize=(16, 16))
for ax, (name, vals) in zip(axs, triggers.items()):
    ax.hist(vals[0], vals[1])
    ax.text(0.65, 0.90, name, transform=ax.transAxes, fontsize=16, verticalalignment='top', bbox=bprops)
fig.text(0.5, 0.95, 'Calorimeter Triggers', ha='center', fontsize=16)
fig.savefig(os.path.join(output_dir, 'run{}_triggers.png'.format(run)))


# figures for signal channels
ncols, nrows = auto_split(len(channels))
figsize = (ncols*6, nrows*4)

# pos
bins = np.arange(-62, 62, step=1)
fig, axs = plt.subplots(nrows, ncols, figsize=figsize, sharex='all', sharey='all')
for i, ax in enumerate(axs.flat):
    if i >= len(channels):
        continue
    ch = channels[i]
    mask = df[ch + '_peak'] > min_peak
    ch_vals = df.loc[mask, ch + '_pos'].values
    ch_vals -= df.loc[mask, 'trg_pos'].values
    ch_vals = ch_vals[(ch_vals < random_range[1]) & (ch_vals > random_range[0])]
    ax.text(0.15, 0.90, ch, transform=ax.transAxes, fontsize=16, verticalalignment='top', bbox=bprops)
    hvals = ax.hist(ch_vals, bins)
    # ax.set_ylim(0, 60000)
fig.tight_layout(rect=(0.03, 0.05, 0.98, 0.95))
fig.text(0.5, 0.02, 'Sample Number', ha='center', fontsize=16)
fig.text(0.02, 0.5, 'Counts', ha='center', rotation=90, fontsize=16)
fig.savefig(os.path.join(output_dir, 'run{}_pos.png'.format(run)))


# peak
spe_fit = pd.DataFrame(columns=['p0', 'p1', 'p2'])
bins = np.arange(0, 500, step=2)
indices = (bins[1:] + bins[:-1])/2.
fig, axs = plt.subplots(nrows, ncols, figsize=figsize, sharex='all', sharey='all', gridspec_kw={'hspace': 0., 'wspace': 0.})
lines, labels = [], []
for i, ax in enumerate(axs.flat):
    if i >= len(channels):
        continue
    ch = channels[i]
    mask = (df[ch + '_peak'] > min_peak)
    ch_vals = df.loc[mask, ch + '_peak'].values
    ch_poses = df.loc[mask, ch + '_pos'].values - df.loc[mask, 'trg_pos'].values
    pmask = (ch_poses < random_range[1]) & (ch_poses > random_range[0])
    ch_vals = ch_vals[pmask]
    # raw data
    vals = pd.Series(index=indices, data=np.histogram(ch_vals, bins)[0])
    # ax.errorbar(x=indices, y=vals, yerr=np.sqrt(vals), fmt='bo', fillstyle='none',
    #             capsize=2, markersize=2.0, label='Data')
    ax.bar(indices, vals, width=np.diff(bins).mean(), color='royalblue', alpha=1.0, label='Data')

    # background
    scale = np.interp(df_bk[ch].idxmax(), indices, vals.values)/df_bk[ch].max()
    # scale = np.sum(np.interp(np.arange(26, 27, step=1), indices, vals.values)) \
    #       / np.sum(np.interp(np.arange(26, 27, step=1), df_bk.index.values, df_bk[ch].values))
    bk = np.interp(indices, df_bk.index.values, df_bk[ch].values)*scale
    ax.plot(indices, bk, 'r--', label='Dark Current')

    # subtracted
    subvals = np.where(vals.values - bk < 0, 0, vals.values - bk)
    ax.bar(indices, subvals, width=np.diff(bins).mean(), color='lightskyblue', alpha=1.0, label='Subtracted Data')
    # ax.errorbar(x=indices, y=(vals.values - bk), yerr=np.sqrt(vals), fmt='ko',
    #             capsize=2, markersize=2.0, label='Subtracted')

    # # fit
    mask = (indices >= 40) & (indices <= 110)
    x, y = indices[mask], subvals[mask]
    sigma = np.where(np.sqrt(y) < 5, 5, np.sqrt(y))
    popt, pcov = curve_fit(gaus, x, y, p0=[100, 80, 15], sigma=sigma, absolute_sigma=True)
    ax.plot(vals.index.values, gaus(vals.index.values, *popt), 'k-', label='Fit')
    spe_fit.loc[ch] = popt

    # text box
    ax.text(0.5, 0.90, ch + '\n' + r'{:.2f} $\pm$ {:.2f}'.format(popt[1], np.abs(popt[2])),
            transform=ax.transAxes, fontsize=24, verticalalignment='top', bbox=bprops)
    ax.tick_params(direction='in', which='both', labelsize=20)
    lines, labels = ax.get_legend_handles_labels()

fig.tight_layout(rect=(0.03, 0.03, 0.99, 0.95))
fig.legend(lines, labels, loc='upper center', ncol=5, fontsize=24)
fig.text(0.5, 0.02, 'ADC Value', ha='center', fontsize=24)
fig.text(0.02, 0.5, 'Counts', ha='center', rotation=90, fontsize=24)
fig.savefig(os.path.join(output_dir, 'run{}_peak.png'.format(run)))

spe_fit.to_csv(os.path.join(data_dir, 'run{}_single_pe.csv'.format(run)))
